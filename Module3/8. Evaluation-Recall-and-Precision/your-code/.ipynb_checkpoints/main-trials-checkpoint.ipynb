{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\")\n",
    "#mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "pixel4      0.0\n",
       "pixel5      0.0\n",
       "           ... \n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "pixel784    0.0\n",
       "Name: 36000, Length: 784, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2387ef58160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot single row\n",
    "import matplotlib\n",
    "\n",
    "reshaped = X.iloc[36000].values.reshape(28, 28)\n",
    "plt.imshow(reshaped, cmap=matplotlib.cm.binary, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is an image of y value\n",
    "y.iloc[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split by index\n",
    "X_train = X.iloc[:60000]\n",
    "X_test = X.iloc[60000:]\n",
    "y_train = y.iloc[:60000]\n",
    "y_test = y.iloc[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate rows with output 5\n",
    "just5s = np.where(y=='5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign train-test split\n",
    "X_train_5 = X.iloc[just5s][:60000]\n",
    "X_test_5 = X.iloc[just5s][60000:]\n",
    "y_train_5 = y.iloc[just5s]\n",
    "y_test_5 = y_test.iloc[just5s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: class, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: '5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17352/685087532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1552\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1554\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1555\u001b[0m                 \u001b[1;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m                 \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: '5'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_5, y_train_5)\n",
    "pred_5 = lr.predict(X_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([  68,   20,   41,  194,   59, 5569,   93,   21,  195,   53],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return prediction frequencies\n",
    "np.unique(pred_5, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821479486773325"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency of 5s is much higher than for other numbers, the prediction worked pretty good\n",
    "5569/sum([  68,   20,   41,  194,   59, 5569,   93,   21,  195,   53])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = X.iloc[36000].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shinemet\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['4'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(nine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The value predicted is wrong!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf.fit(X_test_5, y_train)\n",
    "never_5 = never_5_clf.predict(X_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False]), array([6313], dtype=int64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return prediction frequencies: always False\n",
    "np.unique(never_5, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([ 744, 5569], dtype=int64))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first convert pred_5 to binary class\n",
    "binary_5 = np.where(pred_5=='5', True, False)\n",
    "np.unique(binary_5, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also convert y_test_5 to binary\n",
    "y_test_5_binary = np.where(y_test_5=='5', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for pred_5: \n",
      "[[   0    0]\n",
      " [ 744 5569]]\n",
      "1.0\n",
      "0.8821479486773325\n",
      "0.9373842787409526\n"
     ]
    }
   ],
   "source": [
    "# compare metrics of both models\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Metrics for pred_5: \")\n",
    "print(metrics.confusion_matrix(y_test_5_binary, binary_5))\n",
    "print(metrics.precision_score(y_test_5_binary, binary_5))\n",
    "print(metrics.recall_score(y_test_5_binary, binary_5))\n",
    "print(metrics.f1_score(y_test_5_binary, binary_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for never_5: \n",
      "[[   0    0]\n",
      " [6313    0]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shinemet\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Metrics for never_5: \")\n",
    "print(metrics.confusion_matrix(y_test_5_binary, never_5))\n",
    "print(metrics.precision_score(y_test_5_binary, never_5))\n",
    "print(metrics.recall_score(y_test_5_binary, never_5))\n",
    "print(metrics.f1_score(y_test_5_binary, never_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I should have a higher score on True negatives in never_5 matrix, probably with some good scores on other metrics as well.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Without knowing the model, the dumb classifier metrics could be interpreted as the results of a better fit. We can deduce from this that any model metrics should be considered with regards to the model used.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17352/1865976165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_5_binary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_5_binary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRocCurveDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         return _average_binary_score(\n\u001b[0m\u001b[0;32m    568\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    338\u001b[0m             \u001b[1;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;34m\"is not defined in that case.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_test_5_binary, binary_5))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_5_binary, binary_5)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
